{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877bcfdd-ac63-420b-b4d6-c846b128dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model.roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbd569-6be8-495c-afa6-f861595db0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04142e49-901c-44fa-b3c9-254b0925b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from license_plate_detection.utils import *\n",
    "from fastai.vision.all import *\n",
    "from torchvision.ops import roi_align\n",
    "from license_plate_detection.fpn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e67b8-8bd3-4650-8305-8b65972dd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ROI(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, roi_feat_size=(7,7)):\n",
    "        super().__init__()\n",
    "        self.roi_head= roi_align\n",
    "        self.roi_feat_size= roi_feat_size\n",
    "        self.relu= nn.ReLU()\n",
    "        self.shared_conv= nn.Sequential(*[ConvLayer(in_channels,256,3,2,1), \n",
    "                                          Flatten()])\n",
    "        self.reg_conv= nn.Sequential(*[nn.Linear(4096,num_classes*4)])\n",
    "        self.cls_conv= nn.Sequential(*[nn.Linear(4096,num_classes+1)])\n",
    "        \n",
    "    def get_roi_gt(self, rois, gt_bboxes, gt_labels, size):\n",
    "        rois= TensorPoint(rois[:,:,1:].detach())\n",
    "        gt_bboxes= unscale_pnts(gt_bboxes, size)\n",
    "        gt_roi_cls, gt_roi_reg=[],[]\n",
    "        for idx,_ in enumerate(rois):\n",
    "            flags= assign_anchor_torch(rois[idx], \n",
    "                                    gt_bboxes[:idx+1], \n",
    "                                    pos_iou_thr=0.8, \n",
    "                                    neg_iou_thr=0.2)\n",
    "            roi_cls= sample_anchor_torch(rois[idx], flags, 5)\n",
    "            roi_cls[gt_roi_cls==1]= gt_labels[idx]\n",
    "            roi_reg= calc_offset_torch(gt_bboxes[idx], rois[idx])\n",
    "            gt_roi_cls.append(roi_cls)\n",
    "            gt_roi_reg.append(roi_reg)\n",
    "        return torch.stack(gt_roi_cls), torch.stack(gt_roi_reg)\n",
    "    \n",
    "    def forward(self, x, rois):\n",
    "        rois= rois[:,:, [0,2,1,4,3]].contiguous()\n",
    "        roi_reg_feats, roi_cls_feats=[],[]\n",
    "        for r in rois:\n",
    "            roi_feats= self.roi_head(x, r, self.roi_feat_size, spatial_scale=0.125)\n",
    "            shared_feats= self.shared_conv(roi_feats)\n",
    "            reg_feats= self.reg_conv(shared_feats)\n",
    "            cls_feats= self.cls_conv(shared_feats)\n",
    "            cls_feats= F.softmax(cls_feats, dim=1)\n",
    "            roi_reg_feats.append(reg_feats)\n",
    "            roi_cls_feats.append(cls_feats)\n",
    "        return torch.stack(roi_reg_feats), torch.stack(roi_cls_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220d365-dbf5-49a5-8e29-5bc5da470a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clone_sdp",
   "language": "python",
   "name": "clone_sdp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
